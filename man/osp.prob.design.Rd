% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/ospProbDesign.R
\name{osp.prob.design}
\alias{osp.prob.design}
\title{Longstaff-Schwartz RMC algorithm with a variety of regression methods.}
\usage{
osp.prob.design(N, model, subset = 1:N, method = "lm")
}
\arguments{
\item{N}{is the number of paths}

\item{model}{defines the simulator and reward model, with the two main model hooks being 
option payoff  \code{payoff.func} (plus parameters) and stochastic simulator \code{sim.func} (plus parameters)}

\item{subset}{To have out-of-sample paths, specify \code{subset} (e.g 1:1000) to use for testing.
By default everything is in-sample}

\item{method}{a string specifying regression method to use
\itemize{
 \item spline: \code{smooth.spline} from \pkg{base} which only works \emph{in 1D}
 \item randomforest: (from \pkg{randomForest} package) requires \code{rf.maxnode}
 and \code{rf.ntree} (number of trees) model parameters
 \item loess: only works in \emph{1D or 2D}, requires \code{lo.span} model parameter
 \item earth: multivariate regression splines (MARS) using \pkg{earth} package.
 Requires \code{earth.deg} (interaction degree), \code{earth.nk} (max number of terms to keep),
 \code{earth.thresh} params
 \item rvm: relevance vector machine from \pkg{kernlab} package. Optional \code{rvm.kernel}
 model parameter to decide which kernel family to utilize. Default kernel is rbfdot
 \item npreg: kernel regression using \pkg{npreg} package. Can optionally provide \code{np.kertype} 
 (default is "gaussian"); \code{np.regtype} (default is "lc"); \code{np.kerorder} (default is 2)
 \item nnet: neural network using \pkg{nnet}. This is a single-layer neural net. Specify a scalar \code{nn.nodes} 
 to describe the number of nodes at the hidden layer
 \item lm [Default]: linear global regression using \code{model$bases} (required) basis functions 
 (+ constant) which is a function pointer.
 }}

\item{x0}{required part of the model. Can be either a vector of length \code{model$dim} 
or a vector of length \code{model$dim}*N}
}
\value{
a list containing
\itemize{
\item \code{fit} a list containing all the models generated at each time-step. \code{fit[[1]]} is the emulator
at \eqn{t=\Delta t}, the last one is \code{fit[[M-1]]} which is emulator for \eqn{T-\Delta t}.
\item \code{val}: the in-sample pathwise rewards
\item \code{test}: the out-of-sample pathwise rewards
\item \code{p}: the final price (2-vector for in/out-of-sample)
\item \code{timeElapsed} total running time in seconds, based on \code{Sys.time}
}
}
\description{
RMC using probabilistic design: backpropagation along fixed set of paths (a la Longstaff-Schwartz).
All designs are kept in memory. By default produces only an in-sample estimate. Use in conjuction
with \code{\link{forward.sim.policy}} to generate out-of-sample price estimates.
}
\details{
Works with a probabilistic design that requires storing all paths in memory. Specifying \code{subset}
 allows to compute in parallel with the original computation an out-of-sample estimate of the value function
 
 Calls \code{model$payoff.func}, so the latter must be set prior to calling.
 Also needs \code{model$dt}, \code{model$T} for simulation and \code{model$r} for discounting
 
 Calls \code{model$sim.func} to generate forward paths
 
 Emulator is trained only on paths where payoffs are strictly positive
}
\examples{
set.seed(1)
model2d <- list(look.ahead=1,K=40,x0=rep(40,2),sigma=rep(0.2,2),r=0.06,
 div=0, T=1,dt=0.04,dim=2, sim.func=sim.gbm, payoff.func=put.payoff)
 bas22 <- function(x) return(cbind(x[,1],x[,1]^2,x[,2],x[,2]^2,x[,1]*x[,2]))
 model2d$bases <- bas22
 prob.lm <- osp.prob.design(30000,model2d,method="lm",subset=1:15000)
 prob.lm$p
 # yields [1] 1.440918 1.482422
}
