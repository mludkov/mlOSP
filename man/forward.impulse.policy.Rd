% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/mlOSP_utils.R
\name{forward.impulse.policy}
\alias{forward.impulse.policy}
\title{Simulate a payoff of an impulse strategy along a set of forward paths}
\usage{
forward.impulse.policy(x, M, fit, model, mpc = FALSE)
}
\arguments{
\item{x}{is a matrix of starting values

if input \code{x} is a list, then use the grids specified by x}

\item{M}{number of time steps to forward simulate}

\item{fit}{a list of M fitted emulators that determine the functional approximators of 
V(k,x). Supports km, spline, and hetGP objects (anything supported by \code{ospPredict})}

\item{model}{a list containing all model parameters. In particular need
\code{model$impulse.func} for computing the intervention operator (optimal impulse
to consider), \code{model$sim.func} for simulating each step with time step 
\code{model$dt}.}
}
\value{
a list containing:
\itemize{
 \item \code{payoff} (vector) is the resulting payoff NPV from t=0
 \item \code{tau} (vector) number of times impulses were applied on each path
 \item \code{impulses} (matrix) impulse amounts matching tau
 \item \code{paths} ((d+2)-tensor) forward trajectories of the controlled state process
 \item \code{bnd} (vector) impulse target levels for the case of linear impulse costs
}
}
\description{
Simulate a payoff of an impulse strategy along a set of forward paths
}
\details{
Should be used in conjunction with the \code{\link{osp.impulse.control}} function 
that builds the emulators and calls  forward.impulse.policy internally.
}
